{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unexpected instance while processing input tensors for keras functional model. Expecting KerasTensor which is from tf.keras.Input() or output from keras layer call(). Got: [[[[  55.060997    15.221001    48.32     ]\n   [  57.060997    17.221       50.32     ]\n   [  56.060997    16.221       52.32     ]\n   ...\n   [  12.060997   -22.779       12.32     ]\n   [  13.060997   -24.779       12.32     ]\n   [  13.060997   -23.779       11.32     ]]\n\n  [[  56.060997    19.221       54.32     ]\n   [  56.060997    19.221       54.32     ]\n   [  53.060997    17.221       54.32     ]\n   ...\n   [  13.060997   -26.779        9.32     ]\n   [  10.060997   -29.779        2.3199997]\n   [   9.060997   -30.779        1.3199997]]\n\n  [[  53.060997    20.221       56.32     ]\n   [  54.060997    21.221       57.32     ]\n   [  55.060997    22.221       58.32     ]\n   ...\n   [   9.060997   -30.779        2.3199997]\n   [   9.060997   -33.779       -5.6800003]\n   [   7.060997   -35.779       -7.6800003]]\n\n  ...\n\n  [[  26.060997   -24.779     -123.68     ]\n   [ 148.061       68.221      -31.68     ]\n   [ 130.061       44.221      -76.68     ]\n   ...\n   [ -65.939      -21.779     -123.68     ]\n   [ -42.939003   -14.778999  -123.68     ]\n   [ -53.939003   -13.778999  -123.68     ]]\n\n  [[ 151.061       73.221      -19.68     ]\n   [ 148.061       77.221        4.3199997]\n   [ 151.061       87.221      -10.68     ]\n   ...\n   [ -59.939003   -25.779     -123.68     ]\n   [ -58.939003   -24.779     -123.68     ]\n   [ -54.939003   -12.778999  -118.68     ]]\n\n  [[ 151.061       73.221      -18.68     ]\n   [ 148.061       71.221      -23.68     ]\n   [ 120.061       32.221     -114.68     ]\n   ...\n   [ -60.939003   -19.779     -123.68     ]\n   [ -25.939003    -2.7789993 -109.68     ]\n   [ -52.939003   -21.779     -123.68     ]]]\n\n\n [[[ 149.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   ...\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]]\n\n  [[ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   ...\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]]\n\n  [[ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   ...\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]]\n\n  ...\n\n  [[ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   ...\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]]\n\n  [[ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   ...\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]]\n\n  [[ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   ...\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]]]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/krittapas/Documents/year3/image_processing/detect_people_version.ipynb Cell 1\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/krittapas/Documents/year3/image_processing/detect_people_version.ipynb#W0sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m num_style_layers \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(style_layers)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/krittapas/Documents/year3/image_processing/detect_people_version.ipynb#W0sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m# Build the VGG19 network with our batch of images\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/krittapas/Documents/year3/image_processing/detect_people_version.ipynb#W0sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# This will load the VGG19 model with the pre-trained ImageNet weights, without the fully connected layers\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/krittapas/Documents/year3/image_processing/detect_people_version.ipynb#W0sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m model \u001b[39m=\u001b[39m vgg19\u001b[39m.\u001b[39mVGG19(weights\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mimagenet\u001b[39m\u001b[39m'\u001b[39m, include_top\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, input_tensor\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mconcat([content_image, style_image], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/krittapas/Documents/year3/image_processing/detect_people_version.ipynb#W0sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m# Get the outputs of the indicated layers\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/krittapas/Documents/year3/image_processing/detect_people_version.ipynb#W0sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m outputs_dict \u001b[39m=\u001b[39m {layer\u001b[39m.\u001b[39mname: layer\u001b[39m.\u001b[39moutput \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mlayers}\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/image_processing/lib/python3.11/site-packages/keras/applications/vgg19.py:238\u001b[0m, in \u001b[0;36mVGG19\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[1;32m    236\u001b[0m     inputs \u001b[39m=\u001b[39m img_input\n\u001b[1;32m    237\u001b[0m \u001b[39m# Create model.\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m model \u001b[39m=\u001b[39m training\u001b[39m.\u001b[39mModel(inputs, x, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvgg19\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[39m# Load weights.\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[39mif\u001b[39;00m weights \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mimagenet\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/image_processing/lib/python3.11/site-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/image_processing/lib/python3.11/site-packages/keras/engine/functional.py:159\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39m# Check if the inputs contain any intermediate `KerasTensor` (not\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39m# created by tf.keras.Input()). In this case we need to clone the `Node`\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[39m# and `KerasTensor` objects to mimic rebuilding a new model from new\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39m# inputs.  This feature is only enabled in TF2 not in v1 graph mode.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[1;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[0;32m--> 159\u001b[0m         [\n\u001b[1;32m    160\u001b[0m             functional_utils\u001b[39m.\u001b[39mis_input_keras_tensor(t)\n\u001b[1;32m    161\u001b[0m             \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(inputs)\n\u001b[1;32m    162\u001b[0m         ]\n\u001b[1;32m    163\u001b[0m     ):\n\u001b[1;32m    164\u001b[0m         inputs, outputs \u001b[39m=\u001b[39m functional_utils\u001b[39m.\u001b[39mclone_graph_nodes(\n\u001b[1;32m    165\u001b[0m             inputs, outputs\n\u001b[1;32m    166\u001b[0m         )\n\u001b[1;32m    167\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_graph_network(inputs, outputs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/image_processing/lib/python3.11/site-packages/keras/engine/functional.py:160\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39m# Check if the inputs contain any intermediate `KerasTensor` (not\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39m# created by tf.keras.Input()). In this case we need to clone the `Node`\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[39m# and `KerasTensor` objects to mimic rebuilding a new model from new\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[39m# inputs.  This feature is only enabled in TF2 not in v1 graph mode.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[1;32m    158\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m(\n\u001b[1;32m    159\u001b[0m         [\n\u001b[0;32m--> 160\u001b[0m             functional_utils\u001b[39m.\u001b[39mis_input_keras_tensor(t)\n\u001b[1;32m    161\u001b[0m             \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(inputs)\n\u001b[1;32m    162\u001b[0m         ]\n\u001b[1;32m    163\u001b[0m     ):\n\u001b[1;32m    164\u001b[0m         inputs, outputs \u001b[39m=\u001b[39m functional_utils\u001b[39m.\u001b[39mclone_graph_nodes(\n\u001b[1;32m    165\u001b[0m             inputs, outputs\n\u001b[1;32m    166\u001b[0m         )\n\u001b[1;32m    167\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_graph_network(inputs, outputs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/image_processing/lib/python3.11/site-packages/keras/engine/functional_utils.py:48\u001b[0m, in \u001b[0;36mis_input_keras_tensor\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check if tensor is directly generated from `tf.keras.Input`.\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \n\u001b[1;32m     34\u001b[0m \u001b[39mThis check is useful when constructing the functional model, since we will\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[39m  ValueError: if the tensor is not a KerasTensor instance.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m node_module\u001b[39m.\u001b[39mis_keras_tensor(tensor):\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(_KERAS_TENSOR_TYPE_CHECK_ERROR_MSG\u001b[39m.\u001b[39mformat(tensor))\n\u001b[1;32m     49\u001b[0m \u001b[39mreturn\u001b[39;00m tensor\u001b[39m.\u001b[39mnode\u001b[39m.\u001b[39mis_input\n",
      "\u001b[0;31mValueError\u001b[0m: Found unexpected instance while processing input tensors for keras functional model. Expecting KerasTensor which is from tf.keras.Input() or output from keras layer call(). Got: [[[[  55.060997    15.221001    48.32     ]\n   [  57.060997    17.221       50.32     ]\n   [  56.060997    16.221       52.32     ]\n   ...\n   [  12.060997   -22.779       12.32     ]\n   [  13.060997   -24.779       12.32     ]\n   [  13.060997   -23.779       11.32     ]]\n\n  [[  56.060997    19.221       54.32     ]\n   [  56.060997    19.221       54.32     ]\n   [  53.060997    17.221       54.32     ]\n   ...\n   [  13.060997   -26.779        9.32     ]\n   [  10.060997   -29.779        2.3199997]\n   [   9.060997   -30.779        1.3199997]]\n\n  [[  53.060997    20.221       56.32     ]\n   [  54.060997    21.221       57.32     ]\n   [  55.060997    22.221       58.32     ]\n   ...\n   [   9.060997   -30.779        2.3199997]\n   [   9.060997   -33.779       -5.6800003]\n   [   7.060997   -35.779       -7.6800003]]\n\n  ...\n\n  [[  26.060997   -24.779     -123.68     ]\n   [ 148.061       68.221      -31.68     ]\n   [ 130.061       44.221      -76.68     ]\n   ...\n   [ -65.939      -21.779     -123.68     ]\n   [ -42.939003   -14.778999  -123.68     ]\n   [ -53.939003   -13.778999  -123.68     ]]\n\n  [[ 151.061       73.221      -19.68     ]\n   [ 148.061       77.221        4.3199997]\n   [ 151.061       87.221      -10.68     ]\n   ...\n   [ -59.939003   -25.779     -123.68     ]\n   [ -58.939003   -24.779     -123.68     ]\n   [ -54.939003   -12.778999  -118.68     ]]\n\n  [[ 151.061       73.221      -18.68     ]\n   [ 148.061       71.221      -23.68     ]\n   [ 120.061       32.221     -114.68     ]\n   ...\n   [ -60.939003   -19.779     -123.68     ]\n   [ -25.939003    -2.7789993 -109.68     ]\n   [ -52.939003   -21.779     -123.68     ]]]\n\n\n [[[ 149.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   ...\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]]\n\n  [[ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   ...\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]]\n\n  [[ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   ...\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]]\n\n  ...\n\n  [[ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   ...\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]]\n\n  [[ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   ...\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]]\n\n  [[ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   ...\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]\n   [ 151.061      138.22101    131.32     ]]]]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import vgg19\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load the content and style images\n",
    "content_image_path = 'mountain.jpg'\n",
    "style_image_path = 'starrynight.jpg'\n",
    "\n",
    "# Image preprocessing and deprocessing utilities\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg19.preprocess_input(img)\n",
    "    return tf.convert_to_tensor(img)\n",
    "\n",
    "def deprocess_image(x):\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "# Define content and style layers\n",
    "content_layers = ['block5_conv2']\n",
    "style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
    "\n",
    "# Load VGG19 model\n",
    "model = vgg19.VGG19(weights='imagenet', include_top=False)\n",
    "\n",
    "# Get feature extractors\n",
    "content_model = Model(inputs=model.input, outputs=[model.get_layer(layer).output for layer in content_layers])\n",
    "style_model = Model(inputs=model.input, outputs=[model.get_layer(layer).output for layer in style_layers])\n",
    "\n",
    "# Get content and style features\n",
    "content_image_features = content_model(preprocess_image(content_image_path))\n",
    "style_image_features = style_model(preprocess_image(style_image_path))\n",
    "\n",
    "# ... Rest of the style transfer code . \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
